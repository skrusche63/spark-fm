akka {
  loglevel = INFO
  stdout-loglevel = INFO
  akka.loggers = ["akka.event.slf4j.Slf4jLogger"]
}

actor {
  duration = 10
  retries = 10  
  timeout = 10
}

#
# Access to cassandra is provided by Datastax' spark-cassandra-connector; the respective
# configuration parameters can be retrieved from here: 
#
# https://github.com/datastax/spark-cassandra-connector/blob/master/doc/0_quick_start.md
#
cassandra {
  spark.cassandra.connection.host="127.0.0.1"
}

# Access parameters to order and item related data
# in an Elasticsearch index; note, that the fields
# must be comaptible to the field specification
elastic {
  es.nodes="localhost"
  es.port="9200"
  es.resource=""                
  es.query=""                          
}

file {
  path="/Work/tmp/fm/input.txt"
}

model {
  # Path to the directory where all models are saved
  base=""
}

mongo {
  mongo.input.uri="mongodb://127.0.0.1:27017/beowulf.input"
}

mysql {
  url="127.0.0.1:8889"
  database="analytics"    
  user="root"
  password="root" 
}

redis {
  host="127.0.0.1"
  port="6379"
}
#
# Configuration parameters for the REST API
# of the Factorization Engine
#
rest {
  host="127.0.0.1"
  port=9000
}

spark {
  spark.executor.memory="1g"
  spark.kryoserializer.buffer.mb="256"
}